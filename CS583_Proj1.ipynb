{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 583 Project 1\n",
    "\n",
    "### Fangda Fan, Xiaohan Liu\n",
    "\n",
    "- Implement: MS-Apriori (excluding rule generation)\n",
    "- Consider: multiple minimum supports, support difference constraint, and item constraints\n",
    "- Item constraints: Two types\n",
    "    - Cannotâ€“be-together: sets of items cannot be in the same itemsets (pairwise), \n",
    "        - e.g., {1, 2, 3} and {6, 7, 9, 10}\n",
    "    - Must-have: every itemset must have, \n",
    "        - e.g., (1 or 2)\n",
    "- Deadline: Feb 9, 2017 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data and Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def input_args(file_args):\n",
    "    ms = dict()\n",
    "    sdc = 1\n",
    "    x_cannot = []\n",
    "    x_must = []\n",
    "    for i in open(file_args, \"r\"):\n",
    "        i = i.rstrip(\"\\n\")\n",
    "        if i.startswith(\"MIS\"):\n",
    "            j = i.split(\" = \")\n",
    "            ms.update({j[0][4:-1]: float(j[1])})\n",
    "        elif i.startswith(\"SDC\"):\n",
    "            sdc = float(i.split(\"=\")[1])\n",
    "        elif i.startswith(\"cannot_be_together\"):\n",
    "            x_cannot = [j.split(\", \") for j in i.split(\": \")[1][1:-1].split(\"}, {\")]\n",
    "        elif i.startswith(\"must\"):\n",
    "            x_must = [j for j in i.split(\": \")[1].split(\" or \")]\n",
    "    op = {\"ms\": ms, \"sdc\": sdc, \"x_cannot\": x_cannot, \"x_must\": x_must}\n",
    "    return(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ms': {'10': 0.43,\n",
       "  '100': 0.1,\n",
       "  '120': 0.2,\n",
       "  '140': 0.15,\n",
       "  '20': 0.3,\n",
       "  '30': 0.3,\n",
       "  '40': 0.4,\n",
       "  '50': 0.4,\n",
       "  '60': 0.3,\n",
       "  '70': 0.2,\n",
       "  '80': 0.2,\n",
       "  '90': 0.2},\n",
       " 'sdc': 0.1,\n",
       " 'x_cannot': [['20', '40'], ['70', '80']],\n",
       " 'x_must': ['20', '40', '50']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_args = \"proj1_parameter-file.txt\"\n",
    "file_data = \"proj1_input-data.txt\"\n",
    "#file_args = \"proj1_ex13_args.txt\"\n",
    "#file_data = \"proj1_ex13_data.txt\"\n",
    "\n",
    "args = input_args(file_args)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index-item dictionary: {0: '100', 1: '140', 2: '120', 3: '70', 4: '80', 5: '90', 6: '20', 7: '30', 8: '60', 9: '40', 10: '50', 11: '10'}\n",
      "MIS index {0: 0.10000000000000001, 1: 0.14999999999999999, 2: 0.20000000000000001, 3: 0.20000000000000001, 4: 0.20000000000000001, 5: 0.20000000000000001, 6: 0.29999999999999999, 7: 0.29999999999999999, 8: 0.29999999999999999, 9: 0.40000000000000002, 10: 0.40000000000000002, 11: 0.42999999999999999}\n",
      "Cannot-be-Together index: [(6, 9), (3, 4)]\n",
      "Must-have: [6, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "ms = pd.Series(args[\"ms\"], name = \"MIS\").sort_values().reset_index()\n",
    "id_dict = ms[\"index\"].to_dict()\n",
    "ms_dict = ms[\"MIS\"].to_dict()\n",
    "id_dict_inv = {val: key for key, val in id_dict.items()}\n",
    "x_must = [id_dict_inv[i] for i in args[\"x_must\"]]\n",
    "x_cannot = [tuple(np.sort([id_dict_inv[j] for j in i])) for i in args[\"x_cannot\"]]\n",
    "print(\"Index-item dictionary:\", id_dict)\n",
    "print(\"MIS index\", ms_dict)\n",
    "print(\"Cannot-be-Together index:\",  x_cannot)\n",
    "print(\"Must-have:\", x_must)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def input_data(file_data, columns):\n",
    "    s = pd.read_csv(file_data, header = None, sep = \"\\t\",squeeze = True)\n",
    "    op = s.str[1:-1].str.get_dummies(sep = \", \").reindex(columns = columns, fill_value = 0)\n",
    "    return(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>index</th>\n",
       "      <th>100</th>\n",
       "      <th>140</th>\n",
       "      <th>120</th>\n",
       "      <th>70</th>\n",
       "      <th>80</th>\n",
       "      <th>90</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>60</th>\n",
       "      <th>40</th>\n",
       "      <th>50</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "index  100  140  120  70  80  90  20  30  60  40  50  10\n",
       "0        0    0    0   1   1   1   1   1   0   0   1   0\n",
       "1        0    0    0   1   1   0   1   0   0   0   0   1\n",
       "2        0    0    0   0   1   0   1   0   0   0   0   1\n",
       "3        0    0    0   0   1   0   1   1   0   0   0   0\n",
       "4        0    0    0   0   1   0   1   0   0   0   0   0\n",
       "5        1    1    1   1   1   1   1   1   0   0   1   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = input_data(file_data, ms[\"index\"])\n",
    "X = da.values\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sup(xL):\n",
    "    op = np.mean([X[:, i].all(axis = 1) for i in xL], axis = 1)\n",
    "    return(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0,), (1,), (2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,)],\n",
       " {(0,): 0.16666666666666666,\n",
       "  (1,): 0.16666666666666666,\n",
       "  (2,): 0.16666666666666666,\n",
       "  (3,): 0.5,\n",
       "  (4,): 1.0,\n",
       "  (5,): 0.33333333333333331,\n",
       "  (6,): 1.0,\n",
       "  (7,): 0.5,\n",
       "  (8,): 0.0,\n",
       "  (9,): 0.0,\n",
       "  (10,): 0.33333333333333331,\n",
       "  (11,): 0.33333333333333331})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = [(i,) for i, ival in enumerate(ms_dict)]\n",
    "Isup = sup(I)\n",
    "sup_dict = dict(zip(I, Isup))\n",
    "I, sup_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Candidate Generation\n",
    "### Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 10, 11],\n",
       " [[(0,), (1,), (3,), (4,), (5,), (6,), (7,)]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Li = (Isup > ms[\"MIS\"]).argmax()\n",
    "L = [i for i in range(Li, ms.shape[0]) if Isup[i] > ms[\"MIS\"][Li]]\n",
    "F = [[(i,) for i in np.where(Isup > ms[\"MIS\"])[0]]]\n",
    "Li, L, F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level $\\geq$ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_sup_mis(x):\n",
    "    x_t = x[:, np.newaxis]\n",
    "    x_sup = sup(x_t)\n",
    "    x_mis = [ms_dict[i] for i in x]\n",
    "    x_sup_t = x_sup[:, np.newaxis]\n",
    "    iL = sp.coo_matrix(np.triu((x_sup_t >= x_mis).T & (np.abs(x_sup_t - x_sup) < args[\"sdc\"]), 1)).nonzero()\n",
    "    op = list(zip(x[iL[0]], x[iL[1]]))\n",
    "    return(op)\n",
    "def frequent(xL):\n",
    "    x_sup = sup(xL)\n",
    "    sup_dict.update(dict(zip(xL, x_sup)))\n",
    "    op = [xL[j] for j in np.where(x_sup >= [ms_dict[i[0]] for i in xL])[0]]\n",
    "    xL_dropfirst = set(tuple(i[1:]) for i in xL)\n",
    "    sup_dict.update(dict(zip(xL_dropfirst, sup(xL_dropfirst))))\n",
    "    return(op)\n",
    "def append_set(xL, x_base):\n",
    "    if len(xL):\n",
    "        op = [tuple(i) for i in np.hstack([np.tile(x_base, (len(xL), 1)), xL])]\n",
    "    else:\n",
    "        op = []\n",
    "    return(op)\n",
    "def prune_candidate(xL):\n",
    "    if xL:\n",
    "        op = [xL[l] for l in np.where(np.all([[any(set(k).issubset(j) for k in F[-1]) for j in np.delete(xL, i, axis = 1)] for i in range(1, len(xL[0]))], axis = 0))[0]]\n",
    "    else:\n",
    "        op = []\n",
    "    return(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (0, 2), (1, 2), (3, 7), (4, 6), (5, 10), (5, 11)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = [i for i in pair_sup_mis(np.array(L)) if i[0] in np.array(F[0]).T[0]]\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0,), (1,), (3,), (4,), (5,), (6,), (7,)],\n",
       " [(0, 1), (0, 2), (1, 2), (3, 7), (4, 6), (5, 10)],\n",
       " [(0, 1, 2)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while C:\n",
    "    F.append(frequent(C))\n",
    "    Ls = pd.DataFrame(F[-1])\n",
    "    C = sum([append_set(pair_sup_mis(group.values), name) for name, group in Ls.groupby(list(range(len(F)-1)))[len(F)-1]], [])\n",
    "    C = prune_candidate(C)\n",
    "F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune with Item Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(6,)], [(4, 6), (5, 10)], []]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_prune = [[j for j in i if any(k in j for k in x_must) & ~any(set(k).issubset(j) for k in x_cannot)] for i in F]\n",
    "F_prune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Supports for Association Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0,): 0.16666666666666666,\n",
       " (0, 1): 0.16666666666666666,\n",
       " (0, 1, 2): 0.16666666666666666,\n",
       " (0, 2): 0.16666666666666666,\n",
       " (1,): 0.16666666666666666,\n",
       " (1, 2): 0.16666666666666666,\n",
       " (2,): 0.16666666666666666,\n",
       " (3,): 0.5,\n",
       " (3, 7): 0.33333333333333331,\n",
       " (4,): 1.0,\n",
       " (4, 6): 1.0,\n",
       " (5,): 0.33333333333333331,\n",
       " (5, 10): 0.33333333333333331,\n",
       " (5, 11): 0.0,\n",
       " (6,): 1.0,\n",
       " (7,): 0.5,\n",
       " (8,): 0.0,\n",
       " (9,): 0.0,\n",
       " (10,): 0.33333333333333331,\n",
       " (11,): 0.33333333333333331}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sup_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent 1-itemsets\n",
      "\n",
      "\t6 : {20}\n",
      "\n",
      "Total number of frequent 1-itemsets = 1\n",
      "\n",
      "\n",
      "Frequent 2-itemsets\n",
      "\n",
      "\t6 : {80, 20}\n",
      "Tailcount = 6\n",
      "\t2 : {90, 50}\n",
      "Tailcount = 2\n",
      "\n",
      "Total number of frequent 2-itemsets = 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def output_frequent(F):\n",
    "    op = []\n",
    "    for i, ival in enumerate(F):\n",
    "        if ival:\n",
    "            op.append(\"Frequent {}-itemsets\\n\".format(i+1))\n",
    "            if i == 0:\n",
    "                op += [\"\\t{} : {}\".format(int(sup_dict[j]*len(da)), {int(id_dict[k]) for k in j}) for j in ival]\n",
    "            else:\n",
    "                op += [\"\\t{} : {}\\nTailcount = {}\".format(int(sup_dict[j]*len(da)), {int(id_dict[k]) for k in j}, int(sup_dict[j[1:]]*len(da))) for j in ival]\n",
    "            op.append(\"\\nTotal number of frequent {}-itemsets = {}\\n\\n\".format(i+1, len(ival)))\n",
    "    print(\"\\n\".join(op))\n",
    "output_frequent(F_prune)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
